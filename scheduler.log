  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2025-09-09 22:11:00 +0200] [7813] [INFO] Starting gunicorn 23.0.0
[2025-09-09T22:11:00.445+0200] {scheduler_job_runner.py:1022} INFO - Starting the scheduler
[2025-09-09 22:11:00 +0200] [7813] [INFO] Listening at: http://[::]:8793 (7813)
[2025-09-09 22:11:00 +0200] [7813] [INFO] Using worker: sync
[2025-09-09T22:11:00.458+0200] {executor_loader.py:269} INFO - Loaded executor: :LocalExecutor:
[2025-09-09 22:11:00 +0200] [7814] [INFO] Booting worker with pid: 7814
[2025-09-09 22:11:00 +0200] [7815] [INFO] Booting worker with pid: 7815
[2025-09-09T22:11:00.540+0200] {scheduler_job_runner.py:2218} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-09T22:16:00.721+0200] {scheduler_job_runner.py:2218} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-09T22:20:00.433+0200] {scheduler_job_runner.py:1702} INFO - DAG Fetch--Reddit--GDPR--CSV is at (or above) max_active_runs (1 of 1), not creating any more runs
[2025-09-09T22:20:00.722+0200] {scheduler_job_runner.py:461} INFO - 1 tasks up for execution:
	<TaskInstance: Fetch--Reddit--GDPR--CSV.Get-SubReddit-Italytravel-CSV scheduled__2025-09-09T20:20:00+00:00 [scheduled]>
[2025-09-09T22:20:00.724+0200] {scheduler_job_runner.py:533} INFO - DAG Fetch--Reddit--GDPR--CSV has 0/16 running and queued tasks
[2025-09-09T22:20:00.725+0200] {scheduler_job_runner.py:672} INFO - Setting the following tasks to queued state:
	<TaskInstance: Fetch--Reddit--GDPR--CSV.Get-SubReddit-Italytravel-CSV scheduled__2025-09-09T20:20:00+00:00 [scheduled]>
[2025-09-09T22:20:00.731+0200] {scheduler_job_runner.py:778} INFO - Trying to enqueue tasks: [<TaskInstance: Fetch--Reddit--GDPR--CSV.Get-SubReddit-Italytravel-CSV scheduled__2025-09-09T20:20:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)
[2025-09-09T22:20:00.762+0200] {local_executor.py:61} INFO - Worker starting up pid=8121
2025-09-09 22:20:00 [info     ] Secrets backends loaded for worker [supervisor] backend_classes=['EnvironmentVariablesBackend'] count=1
/home/tahmast/myenv/lib/python3.12/site-packages/airflow/sdk/execution_time/supervisor.py:476 DeprecationWarning: This process (pid=8121) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-09-09T22:20:02.645+0200] {_client.py:1025} INFO - HTTP Request: PATCH http://localhost:8080/execution/task-instances/01993022-a32b-7509-b475-0c3b4081567d/run "HTTP/1.1 200 OK"
2025-09-09 22:20:02 [debug    ] Sending                        [supervisor] msg=StartupDetails(ti=TaskInstance(id=UUID('01993022-a32b-7509-b475-0c3b4081567d'), task_id='Get-SubReddit-Italytravel-CSV', dag_id='Fetch--Reddit--GDPR--CSV', run_id='scheduled__2025-09-09T20:20:00+00:00', try_number=1, map_index=-1, pool_slots=1, queue='default', priority_weight=2, executor_config={}, parent_context_carrier={}, context_carrier=None, queued_dttm=None), dag_rel_path='Fetch_reddit.py', bundle_info=BundleInfo(name='dags-folder', version=None), start_date=datetime.datetime(2025, 9, 9, 20, 20, 0, 976269, tzinfo=datetime.timezone.utc), ti_context=TIRunContext(dag_run=DagRun(dag_id='Fetch--Reddit--GDPR--CSV', run_id='scheduled__2025-09-09T20:20:00+00:00', logical_date=datetime.datetime(2025, 9, 9, 20, 20, tzinfo=TzInfo(UTC)), data_interval_start=datetime.datetime(2025, 9, 9, 20, 20, tzinfo=TzInfo(UTC)), data_interval_end=datetime.datetime(2025, 9, 9, 20, 20, tzinfo=TzInfo(UTC)), run_after=datetime.datetime(2025, 9, 9, 20, 20, tzinfo=TzInfo(UTC)), start_date=datetime.datetime(2025, 9, 9, 20, 20, 0, 487619, tzinfo=TzInfo(UTC)), end_date=None, clear_number=0, run_type=<DagRunType.SCHEDULED: 'scheduled'>, state=<DagRunState.RUNNING: 'running'>, conf={}, consumed_asset_events=[]), task_reschedule_count=0, max_tries=5, variables=[], connections=[], upstream_map_indexes={}, next_method=None, next_kwargs=None, xcom_keys_to_clear=[], should_retry=True), type='StartupDetails')
[2025-09-09T22:20:02.702+0200] {_client.py:1025} INFO - HTTP Request: PUT http://localhost:8080/execution/task-instances/01993022-a32b-7509-b475-0c3b4081567d/heartbeat "HTTP/1.1 204 No Content"
2025-09-09 22:20:02 [debug    ] Received message from task runner [supervisor] msg=SetRenderedFields(rendered_fields={'templates_dict': None, 'op_args': [], 'op_kwargs': {}}, type='SetRenderedFields')
[2025-09-09T22:20:02.807+0200] {_client.py:1025} INFO - HTTP Request: PUT http://localhost:8080/execution/task-instances/01993022-a32b-7509-b475-0c3b4081567d/rtif "HTTP/1.1 201 Created"
2025-09-09 22:20:03 [debug    ] Received message from task runner [supervisor] msg=SetXCom(key='return_value', value='/home/tahmast/airflow/data/italytravel_20250909T202000.csv', dag_id='Fetch--Reddit--GDPR--CSV', run_id='scheduled__2025-09-09T20:20:00+00:00', task_id='Get-SubReddit-Italytravel-CSV', map_index=-1, mapped_length=None, type='SetXCom')
[2025-09-09T22:20:03.831+0200] {_client.py:1025} INFO - HTTP Request: POST http://localhost:8080/execution/xcoms/Fetch--Reddit--GDPR--CSV/scheduled__2025-09-09T20:20:00+00:00/Get-SubReddit-Italytravel-CSV/return_value "HTTP/1.1 201 Created"
2025-09-09 22:20:03 [debug    ] Received message from task runner [supervisor] msg=SucceedTask(state='success', end_date=datetime.datetime(2025, 9, 9, 20, 20, 3, 833419, tzinfo=datetime.timezone.utc), task_outlets=[], outlet_events=[], rendered_map_index=None, type='SucceedTask')
[2025-09-09T22:20:03.900+0200] {_client.py:1025} INFO - HTTP Request: PATCH http://localhost:8080/execution/task-instances/01993022-a32b-7509-b475-0c3b4081567d/state "HTTP/1.1 204 No Content"
2025-09-09 22:20:03 [info     ] Task finished                  [supervisor] duration=2.95743980799989 exit_code=0 final_state=success
[2025-09-09T22:20:04.035+0200] {scheduler_job_runner.py:835} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='Fetch--Reddit--GDPR--CSV', task_id='Get-SubReddit-Italytravel-CSV', run_id='scheduled__2025-09-09T20:20:00+00:00', try_number=1, map_index=-1)
[2025-09-09T22:20:04.089+0200] {scheduler_job_runner.py:879} INFO - TaskInstance Finished: dag_id=Fetch--Reddit--GDPR--CSV, task_id=Get-SubReddit-Italytravel-CSV, run_id=scheduled__2025-09-09T20:20:00+00:00, map_index=-1, run_start_date=2025-09-09 20:20:00.976269+00:00, run_end_date=2025-09-09 20:20:03.833419+00:00, run_duration=2.85715, state=success, executor=LocalExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=5, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-09 20:20:00.726909+00:00, scheduled_dttm=2025-09-09 20:20:00.562805+00:00,queued_by_job_id=41, pid=8122
[2025-09-09T22:20:05.172+0200] {dagrun.py:1180} INFO - Marking run <DagRun Fetch--Reddit--GDPR--CSV @ 2025-09-09 20:20:00+00:00: scheduled__2025-09-09T20:20:00+00:00, state:running, queued_at: 2025-09-09 20:20:00.404063+00:00. run_type: scheduled> successful
[2025-09-09T22:20:05.174+0200] {dagrun.py:1238} INFO - DagRun Finished: dag_id=Fetch--Reddit--GDPR--CSV, logical_date=2025-09-09 20:20:00+00:00, run_id=scheduled__2025-09-09T20:20:00+00:00, run_start_date=2025-09-09 20:20:00.487619+00:00, run_end_date=2025-09-09 20:20:05.174194+00:00, run_duration=4.686575, state=success, run_type=scheduled, data_interval_start=2025-09-09 20:20:00+00:00, data_interval_end=2025-09-09 20:20:00+00:00,
[2025-09-09T22:20:05.191+0200] {dag.py:2236} INFO - Setting next_dagrun for Fetch--Reddit--GDPR--CSV to 2025-09-09 20:30:00+00:00, run_after=2025-09-09 20:30:00+00:00
[2025-09-09T22:21:00.813+0200] {scheduler_job_runner.py:2218} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-09T22:26:00.909+0200] {scheduler_job_runner.py:2218} INFO - Adopting or resetting orphaned tasks for active dag runs
